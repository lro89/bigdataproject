<workflow-app name="TF-IDF-1" xmlns="uri:oozie:workflow:0.4">
  <start to="WordFrequencyInDocument" />
  <action name="WordFrequencyInDocument">
    <map-reduce>
      <job-tracker>${jobTracker}</job-tracker>
      <name-node>${nameNode}</name-node>
      <prepare>
        <delete path="${outputJob1}" />
      </prepare>
      <configuration>
        <property>
          <name>mapred.mapper.new-api</name>
          <value>true</value>
        </property>
        <property>
          <name>mapred.reducer.new-api</name>
          <value>true</value>
        </property>
        <property>
          <name>mapreduce.input.fileinputformat.inputdir</name>
          <value>${inputJob1}</value>
        </property>
        <property>
          <name>mapreduce.job.map.class</name>
          <value>org.fhmuenster.bde.mr.tfidf.WordFrequencyInDocument$WordFrequencyInDocMapper</value>
        </property>
        <property>
          <name>mapreduce.job.output.key.class</name>
          <value>org.apache.hadoop.io.Text</value>
        </property>
        <property>
          <name>mapreduce.job.output.value.class</name>
          <value>org.apache.hadoop.io.IntWritable</value>
        </property>
        <property>
          <name>mapreduce.job.reduce.class</name>
          <value>org.fhmuenster.bde.mr.tfidf.WordFrequencyInDocument$WordFrequencyInDocReducer</value>
        </property>
        <property>
          <name>mapreduce.job.name</name>
          <value>Word Frequency In Document</value>
        </property>
        <property>
          <name>mapreduce.output.fileoutputformat.outputdir</name>
          <value>${outputJob1}</value>
        </property>
      </configuration>
    </map-reduce>
    <ok to="DocsInCorpusList" />
    <error to="kill" />
  </action>
  <action name="DocsInCorpusList">
    <map-reduce>
      <job-tracker>${jobTracker}</job-tracker>
      <name-node>${nameNode}</name-node>
      <prepare>
        <delete path="${outputJob2}" />
      </prepare>
      <configuration>
        <property>
          <name>mapred.mapper.new-api</name>
          <value>true</value>
        </property>
        <property>
          <name>mapred.reducer.new-api</name>
          <value>true</value>
        </property>
        <property>
          <name>mapreduce.input.fileinputformat.inputdir</name>
          <value>${outputJob1}</value>
        </property>
        <property>
          <name>mapreduce.job.map.class</name>
          <value>org.fhmuenster.bde.mr.tfidf.WordCountsInDocuments$WordCountsForDocsMapper</value>
        </property>
        <property>
          <name>mapreduce.job.output.key.class</name>
          <value>org.apache.hadoop.io.Text</value>
        </property>
        <property>
          <name>mapreduce.job.output.value.class</name>
          <value>org.apache.hadoop.io.Text</value>
        </property>
        <property>
          <name>mapreduce.job.reduce.class</name>
          <value>org.fhmuenster.bde.mr.tfidf.WordCountsInDocuments$WordCountsForDocsReducer</value>
        </property>
        <property>
          <name>mapreduce.job.name</name>
          <value>Word Counts</value>
        </property>
        <property>
          <name>mapreduce.output.fileoutputformat.outputdir</name>
          <value>${outputJob2}</value>
        </property>
      </configuration>
    </map-reduce>
    <ok to="NumOfDocsInCorpus" />
    <error to="kill" />
  </action>
  <action name="NumOfDocsInCorpus">
    <map-reduce>
      <job-tracker>${jobTracker}</job-tracker>
      <name-node>${nameNode}</name-node>
      <prepare>
        <delete path="${outputJob3}" />
      </prepare>
      <configuration>
        <property>
          <name>mapred.mapper.new-api</name>
          <value>true</value>
        </property>
        <property>
          <name>mapred.reducer.new-api</name>
          <value>true</value>
        </property>
        <property>
          <name>mapreduce.input.fileinputformat.inputdir</name>
          <value>${outputJob2}</value>
        </property>
        <property>
          <name>mapreduce.job.map.class</name>
          <value>org.fhmuenster.bde.mr.tfidf.WordsInCorpusTFIDF$WordsInCorpusTFIDFMapper</value>
        </property>
        <property>
          <name>mapreduce.job.output.key.class</name>
          <value>org.apache.hadoop.io.Text</value>
        </property>
        <property>
          <name>mapreduce.job.output.value.class</name>
          <value>org.apache.hadoop.io.Text</value>
        </property>
        <property>
          <name>mapreduce.job.reduce.class</name>
          <value>org.fhmuenster.bde.mr.tfidf.WordsInCorpusTFIDF$WordsInCorpusTFIDFReducer</value>
        </property>
        <property>
          <name>mapreduce.job.name</name>
          <value>TF-IDF of Words in Corpus</value>
        </property>
        <property>
          <name>mapreduce.output.fileoutputformat.outputdir</name>
          <value>${outputJob3}</value>
        </property>
      </configuration>
    </map-reduce>
    <ok to="end" />
    <error to="kill" />
  </action>
  <kill name="kill">
    <message>Action failed, error
      message[${wf:errorMessage(wf:lastErrorNode())}]
    </message>
  </kill>
  <end name="end" />
</workflow-app>
